

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Learner Mechanics &mdash; mlens 0.2.2 documentation</title>
  

  
  
  
  

  

  
  
    

  

  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Lato" type="text/css" />
  <link rel="stylesheet" href="../_static/css/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/mlens-theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/sphinx-glr.css" type="text/css" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Layer Mechanics" href="layer.html" />
    <link rel="prev" title="Overview" href="../overview.html" /> 

  
  <script src="../_static/js/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="../index.html">
          

          
            
            <img src="../_static/logo.png" class="logo" alt="Logo"/>
          
          </a>

          
            
            
              <div class="version">
                0.2.2
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Installation</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../start/install.html">Install</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../start/install.html#bleeding-edge">Bleeding edge</a></li>
<li class="toctree-l2"><a class="reference internal" href="../start/install.html#dependencies">Dependencies</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../start/install.html#test-build">Test build</a></li>
</ul>
<p class="caption"><span class="caption-text">High-level API</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="start.html">Getting started</a><ul>
<li class="toctree-l2"><a class="reference internal" href="start.html#preliminaries">Preliminaries</a></li>
<li class="toctree-l2"><a class="reference internal" href="start.html#ensemble-guide">Ensemble guide</a><ul>
<li class="toctree-l3"><a class="reference internal" href="start.html#building-an-ensemble">Building an ensemble</a></li>
<li class="toctree-l3"><a class="reference internal" href="start.html#multi-layer-ensembles">Multi-layer ensembles</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="start.html#model-selection-guide">Model selection guide</a><ul>
<li class="toctree-l3"><a class="reference internal" href="start.html#the-scoring-function">The scoring function</a></li>
<li class="toctree-l3"><a class="reference internal" href="start.html#a-simple-evaluation">A simple evaluation</a></li>
<li class="toctree-l3"><a class="reference internal" href="start.html#preprocessing">Preprocessing</a></li>
<li class="toctree-l3"><a class="reference internal" href="start.html#model-selection-across-preprocessing-pipelines">Model Selection across preprocessing pipelines</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="start.html#visualization-guide">Visualization guide</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="advanced.html">Advanced features tutorial</a><ul>
<li class="toctree-l2"><a class="reference internal" href="advanced.html#propagating-input-features">Propagating input features</a></li>
<li class="toctree-l2"><a class="reference internal" href="advanced.html#probabilistic-ensemble-learning">Probabilistic ensemble learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="advanced.html#advanced-subsemble-techniques">Advanced Subsemble techniques</a></li>
<li class="toctree-l2"><a class="reference internal" href="advanced.html#general-multi-layer-ensemble-learning">General multi-layer ensemble learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="advanced.html#passing-file-paths-as-data-input">Passing file paths as data input</a></li>
<li class="toctree-l2"><a class="reference internal" href="advanced.html#ensemble-model-selection">Ensemble model selection</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../start/ensembles.html">Ready-made ensemble classes</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../start/ensembles.html#super-learner">Super Learner</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../start/ensembles.html#references">References</a></li>
<li class="toctree-l3"><a class="reference internal" href="../start/ensembles.html#notes">Notes</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../start/ensembles.html#subsemble">Subsemble</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../start/ensembles.html#id8">References</a></li>
<li class="toctree-l3"><a class="reference internal" href="../start/ensembles.html#id10">Notes</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../start/ensembles.html#blend-ensemble">Blend Ensemble</a></li>
<li class="toctree-l2"><a class="reference internal" href="../start/ensembles.html#sequential-ensemble">Sequential Ensemble</a></li>
</ul>
</li>
</ul>
<p class="caption"><span class="caption-text">Mechanics</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../overview.html">Overview</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Learner Mechanics</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#the-learner-api">The Learner API</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#basics">Basics</a></li>
<li class="toctree-l3"><a class="reference internal" href="#partitioning">Partitioning</a></li>
<li class="toctree-l3"><a class="reference internal" href="#preprocessing">Preprocessing</a></li>
<li class="toctree-l3"><a class="reference internal" href="#parallel-estimation">Parallel estimation</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="layer.html">Layer Mechanics</a><ul>
<li class="toctree-l2"><a class="reference internal" href="layer.html#the-layer-api">The Layer API</a><ul>
<li class="toctree-l3"><a class="reference internal" href="layer.html#basics">Basics</a></li>
<li class="toctree-l3"><a class="reference internal" href="layer.html#multitasking">Multitasking</a></li>
<li class="toctree-l3"><a class="reference internal" href="layer.html#layer-features">Layer features</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="parallel.html">Parallel Mechanics</a><ul>
<li class="toctree-l2"><a class="reference internal" href="parallel.html#parallelprocessing-api">ParallelProcessing API</a><ul>
<li class="toctree-l3"><a class="reference internal" href="parallel.html#stacking-a-set-of-parallel-jobs">Stacking a set of parallel jobs</a></li>
<li class="toctree-l3"><a class="reference internal" href="parallel.html#manual-initialization-and-processing">Manual initialization and processing</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="sequential.html">Sequential Mechanics</a></li>
</ul>
<p class="caption"><span class="caption-text">Details</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../benchmarks/memory.html">Memory consumption</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../benchmarks/memory.html#memory-mapping">Memory mapping</a></li>
<li class="toctree-l2"><a class="reference internal" href="../benchmarks/memory.html#ml-ensemble-memory-profiling">ML-Ensemble memory profiling</a></li>
<li class="toctree-l2"><a class="reference internal" href="../benchmarks/memory.html#memory-performance-benchmark">Memory performance benchmark</a></li>
<li class="toctree-l2"><a class="reference internal" href="../benchmarks/memory.html#gotcha-s">Gotcha’s</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../benchmarks/benchmarks.html">Performance benchmarks</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../benchmarks/benchmarks.html#mnist">MNIST</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../benchmarks/benchmarks.html#benchmark">Benchmark</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../benchmarks/benchmarks.html#the-friedman-regression-problem-1">The Friedman Regression Problem 1</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../benchmarks/benchmarks.html#id5">Benchmark</a></li>
<li class="toctree-l3"><a class="reference internal" href="../benchmarks/benchmarks.html#references">References</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../benchmarks/scaling.html">Scale benchmarks</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../benchmarks/scaling.html#single-process-vs-multi-process">Single process vs multi-process</a></li>
<li class="toctree-l2"><a class="reference internal" href="../benchmarks/scaling.html#ensemble-comparison">Ensemble comparison</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../deep/troubleshooting.html">Troubleshooting</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../deep/troubleshooting.html#bad-interaction-with-third-party-packages">Bad interaction with third-party packages</a></li>
<li class="toctree-l2"><a class="reference internal" href="../deep/troubleshooting.html#array-copying-during-fitting">Array copying during fitting</a></li>
</ul>
</li>
</ul>
<p class="caption"><span class="caption-text">Additional Information</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../misc/license.html">License</a></li>
<li class="toctree-l1"><a class="reference internal" href="../misc/updates.html">Change log</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">mlens</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html">Docs</a> &raquo;</li>
        
      <li>Learner Mechanics</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../_sources/tutorials/learner.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="sphx-glr-download-link-note admonition note">
<p class="first admonition-title">Note</p>
<p class="last">Click <a class="reference internal" href="#sphx-glr-download-tutorials-learner-py"><span class="std std-ref">here</span></a> to download the full example code</p>
</div>
<div class="sphx-glr-example-title section" id="learner-mechanics">
<span id="learner-tutorial"></span><span id="sphx-glr-tutorials-learner-py"></span><h1>Learner Mechanics<a class="headerlink" href="#learner-mechanics" title="Permalink to this headline">¶</a></h1>
<p>ML-Ensemble is designed to provide an easy user interface. But it is also designed
to be extremely flexible, all the wile providing maximum concurrency at minimal
memory consumption. The lower-level API that builds the ensemble and manages the
computations is constructed in as modular a fashion as possible.</p>
<p>The low-level API introduces a computational graph-like environment that you can
directly exploit to gain further control over your ensemble. In fact, building
your ensemble through the low-level API is almost as straight forward as using the
high-level API. In this tutorial, we will walk through the basics <code class="xref py py-class docutils literal notranslate"><span class="pre">Learner</span></code>
and <code class="xref py py-class docutils literal notranslate"><span class="pre">Transformer</span></code> class.</p>
<div class="section" id="the-learner-api">
<h2>The Learner API<a class="headerlink" href="#the-learner-api" title="Permalink to this headline">¶</a></h2>
<div class="section" id="basics">
<h3>Basics<a class="headerlink" href="#basics" title="Permalink to this headline">¶</a></h3>
<p>The base estimator of ML-Ensemble is the <code class="xref py py-class docutils literal notranslate"><span class="pre">Learner</span></code> instance. A learner is a
wrapper around a generic estimator along with a cross-validation strategy. The job
of the learner is to manage all sub-computations required for fitting and prediction.
In fact, it’s public methods are generators from sub-learners, that do the actual
computation.  A learner is the parent node of an estimator’s computational sub-graph
induced by the cross-validation strategy.</p>
<p>A learner is created by specifying an <code class="docutils literal notranslate"><span class="pre">estimator</span></code> and an <code class="docutils literal notranslate"><span class="pre">indexer</span></code>, along with a
set of optional arguments, most notably the <code class="docutils literal notranslate"><span class="pre">name</span></code> of the learner. Naming is important,
is it is used for cache referencing. If setting it manually, ensure you give the learner
a unique name.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mlens.utils.dummy</span> <span class="kn">import</span> <span class="n">OLS</span>
<span class="kn">from</span> <span class="nn">mlens.parallel</span> <span class="kn">import</span> <span class="n">Learner</span><span class="p">,</span> <span class="n">Job</span>
<span class="kn">from</span> <span class="nn">mlens.index</span> <span class="kn">import</span> <span class="n">FoldIndex</span>


<span class="n">indexer</span> <span class="o">=</span> <span class="n">FoldIndex</span><span class="p">(</span><span class="n">folds</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">learner</span> <span class="o">=</span> <span class="n">Learner</span><span class="p">(</span><span class="n">estimator</span><span class="o">=</span><span class="n">OLS</span><span class="p">(),</span>
                  <span class="n">indexer</span><span class="o">=</span><span class="n">indexer</span><span class="p">,</span>
                  <span class="n">name</span><span class="o">=</span><span class="s1">&#39;ols&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p>The learner doesn’t do any heavy lifting itself, it manages the creation a sub-graph
of auxiliary <code class="xref py py-class docutils literal notranslate"><span class="pre">SubLearner</span></code> nodes for each fold during estimation.
This process is dynamic: the sub-learners are temporary instances created for each
estimation.</p>
<p>To fit a learner, we need a cache reference. When fitting all estimators from the
main process, this reference can be a list. If not (e.g. multiprocessing), the
reference should instead be a <code class="docutils literal notranslate"><span class="pre">str</span></code> pointing to the path of the cache directory.
Prior to running a job (<code class="docutils literal notranslate"><span class="pre">fit</span></code>, <code class="docutils literal notranslate"><span class="pre">predict</span></code>, <code class="docutils literal notranslate"><span class="pre">transform</span></code>), the learner must be
configured on the given data by calling the <code class="docutils literal notranslate"><span class="pre">setup</span></code> method. This takes cares of
indexing the training set for cross-validation, assigning output columns et.c.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">os</span><span class="o">,</span> <span class="nn">tempfile</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>

<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">20</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>

<span class="c1"># Specify a cache directory</span>
<span class="n">path</span> <span class="o">=</span> <span class="p">[]</span>

<span class="c1"># Run the setup routine</span>
<span class="n">learner</span><span class="o">.</span><span class="n">setup</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="s1">&#39;fit&#39;</span><span class="p">)</span>

<span class="c1"># Run</span>
<span class="k">for</span> <span class="n">sub_learner</span> <span class="ow">in</span> <span class="n">learner</span><span class="o">.</span><span class="n">gen_fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
    <span class="n">sub_learner</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">path</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="s2">&quot;Cached items:</span><span class="se">\n</span><span class="si">%r</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">path</span><span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Cached items:
[(&#39;ols.0.0&#39;, &lt;mlens.parallel.learner.IndexedEstimator object at 0x115b24bf8&gt;), (&#39;ols.0.1&#39;, &lt;mlens.parallel.learner.IndexedEstimator object at 0x115b4a518&gt;), (&#39;ols.0.2&#39;, &lt;mlens.parallel.learner.IndexedEstimator object at 0x115b4a570&gt;)]
</pre></div>
</div>
<p>Fitting the learner puts three copies of the OLS estimator in the <code class="docutils literal notranslate"><span class="pre">path</span></code>:
one for each fold and one for the full dataset.
These are named as <code class="docutils literal notranslate"><span class="pre">[name].[col_id].[fold_id]</span></code>. To load these into the
learner, we need to call <code class="docutils literal notranslate"><span class="pre">collect</span></code>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">learner</span><span class="o">.</span><span class="n">collect</span><span class="p">(</span><span class="n">path</span><span class="p">)</span>
</pre></div>
</div>
<p>The main estimator, fitted on all data, gets stored into the
<code class="docutils literal notranslate"><span class="pre">learner_</span></code> attribute, while the others are stored in the
<code class="docutils literal notranslate"><span class="pre">sublearners_</span></code>. These attributes are generators that create
new sub-learners with fitted estimators when called upon.</p>
<p>To generate predictions, we can either use the <code class="docutils literal notranslate"><span class="pre">sublearners_</span></code>
generator create cross-validated predictions, or <code class="docutils literal notranslate"><span class="pre">learner_</span></code>
generator to generate predictions for the whole input set.</p>
<p>Similarly to above, we predict by specifying the job and the data to use.
Now however, we must also specify the output array to populate.
In particular, the learner will populate the columns given in the
<code class="docutils literal notranslate"><span class="pre">output_columns</span></code> attribute, which is set with the <code class="docutils literal notranslate"><span class="pre">setup</span></code> call. If you
don’t want it to start populating from the first column, you can pass the
<code class="docutils literal notranslate"><span class="pre">n_left_concats</span></code> argument to <code class="docutils literal notranslate"><span class="pre">setup</span></code>. Here, we use the <code class="docutils literal notranslate"><span class="pre">transform</span></code> task,
which uses the <code class="docutils literal notranslate"><span class="pre">sublearners_</span></code> generator to produce cross-validated
predictions.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">path</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">P</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">2</span><span class="p">))</span>
<span class="n">learner</span><span class="o">.</span><span class="n">setup</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="s1">&#39;transform&#39;</span><span class="p">,</span> <span class="n">n_left_concats</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="k">for</span> <span class="n">sub_learner</span> <span class="ow">in</span> <span class="n">learner</span><span class="o">.</span><span class="n">gen_transform</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">P</span><span class="p">):</span>
    <span class="n">sub_learner</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">path</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="s1">&#39;Output:&#39;</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="n">P</span><span class="p">)</span>
    <span class="k">print</span><span class="p">()</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Output:
[[0.         1.60510605]
 [0.         1.46322674]
 [0.         1.32134742]
 [0.         1.17946811]
 [0.         1.03758879]
 [0.         0.        ]
 [0.         0.        ]
 [0.         0.        ]
 [0.         0.        ]
 [0.         0.        ]]

Output:
[[ 0.          1.60510605]
 [ 0.          1.46322674]
 [ 0.          1.32134742]
 [ 0.          1.17946811]
 [ 0.          1.03758879]
 [ 0.          0.1298892 ]
 [ 0.          0.04099401]
 [ 0.         -0.04790118]
 [ 0.         -0.13679637]
 [ 0.         -0.22569156]]
</pre></div>
</div>
<p>In the above loop, a sub-segment of <code class="docutils literal notranslate"><span class="pre">P</span></code> is updated by each sublearner
spawned by the learner. To instead produce predictions for the full
dataset using the estimator fitted on all training data,
task the learner to <code class="docutils literal notranslate"><span class="pre">predict</span></code>.</p>
<p>To streamline job generation across tasks and different classes, ML-Ensemble
features a <code class="xref py py-class docutils literal notranslate"><span class="pre">Job</span></code> class that manages job parameters.
The job class prevents code repetition and allows us to treat the learner
as a callable, enabling task-agnostic code:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">job</span> <span class="o">=</span> <span class="n">Job</span><span class="p">(</span>
    <span class="n">job</span><span class="o">=</span><span class="s1">&#39;predict&#39;</span><span class="p">,</span>
    <span class="n">stack</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span>
    <span class="n">split</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
    <span class="nb">dir</span><span class="o">=</span><span class="p">{},</span>
    <span class="n">targets</span><span class="o">=</span><span class="n">y</span><span class="p">,</span>
    <span class="n">predict_in</span><span class="o">=</span><span class="n">X</span><span class="p">,</span>
    <span class="n">predict_out</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">1</span><span class="p">))</span>
<span class="p">)</span>

<span class="n">learner</span><span class="o">.</span><span class="n">setup</span><span class="p">(</span><span class="n">job</span><span class="o">.</span><span class="n">predict_in</span><span class="p">,</span> <span class="n">job</span><span class="o">.</span><span class="n">targets</span><span class="p">,</span> <span class="n">job</span><span class="o">.</span><span class="n">job</span><span class="p">)</span>
<span class="k">for</span> <span class="n">sub_learner</span> <span class="ow">in</span> <span class="n">learner</span><span class="p">(</span><span class="n">job</span><span class="o">.</span><span class="n">args</span><span class="p">(),</span> <span class="s1">&#39;main&#39;</span><span class="p">):</span>
    <span class="n">sub_learner</span><span class="p">()</span>
    <span class="k">print</span><span class="p">(</span><span class="s1">&#39;Output:&#39;</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="n">job</span><span class="o">.</span><span class="n">predict_out</span><span class="p">)</span>
    <span class="k">print</span><span class="p">()</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Output:
[[0.48329249]
 [0.48795256]
 [0.49261263]
 [0.4972727 ]
 [0.50193277]
 [0.50659285]
 [0.51125292]
 [0.51591299]
 [0.52057306]
 [0.52523313]]
</pre></div>
</div>
<p>ML-Ensemble follows the Scikit-learn API, so if you wish to update any
hyper-parameters of the estimator, use the <code class="docutils literal notranslate"><span class="pre">get_params</span></code> and <code class="docutils literal notranslate"><span class="pre">set_params</span></code>
API:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">print</span><span class="p">(</span><span class="s2">&quot;Params before:&quot;</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">learner</span><span class="o">.</span><span class="n">get_params</span><span class="p">())</span>

<span class="n">learner</span><span class="o">.</span><span class="n">set_params</span><span class="p">(</span><span class="n">estimator__offset</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">indexer__folds</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="s2">&quot;Params after:&quot;</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">learner</span><span class="o">.</span><span class="n">get_params</span><span class="p">())</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Params before:
{&#39;attr&#39;: &#39;predict&#39;, &#39;estimator__offset&#39;: 0, &#39;estimator&#39;: OLS(offset=0), &#39;indexer__X&#39;: None, &#39;indexer__folds&#39;: 2, &#39;indexer__raise_on_exception&#39;: True, &#39;indexer&#39;: FoldIndex(X=None, folds=2, raise_on_exception=True), &#39;name&#39;: &#39;ols&#39;, &#39;preprocess&#39;: None, &#39;proba&#39;: False, &#39;scorer&#39;: None, &#39;backend&#39;: &#39;threading&#39;, &#39;n_jobs&#39;: -1, &#39;dtype&#39;: &lt;class &#39;numpy.float32&#39;&gt;, &#39;raise_on_exception&#39;: True}
Params after:
{&#39;attr&#39;: &#39;predict&#39;, &#39;estimator__offset&#39;: 1, &#39;estimator&#39;: OLS(offset=1), &#39;indexer__X&#39;: None, &#39;indexer__folds&#39;: 3, &#39;indexer__raise_on_exception&#39;: True, &#39;indexer&#39;: FoldIndex(X=None, folds=3, raise_on_exception=True), &#39;name&#39;: &#39;ols&#39;, &#39;preprocess&#39;: None, &#39;proba&#39;: False, &#39;scorer&#39;: None, &#39;backend&#39;: &#39;threading&#39;, &#39;n_jobs&#39;: -1, &#39;dtype&#39;: &lt;class &#39;numpy.float32&#39;&gt;, &#39;raise_on_exception&#39;: True}
</pre></div>
</div>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">Updating the indexer on one learner updates the indexer on all
learners that where initiated with the same instance.</p>
</div>
</div>
<div class="section" id="partitioning">
<h3>Partitioning<a class="headerlink" href="#partitioning" title="Permalink to this headline">¶</a></h3>
<p>We can create several other types of learners by
varying the estimation strategy. An especially interesting strategy is to
partition the training set and create several learners fitted on a given
partition. This will create one prediction feature per partition.
In the following example we fit the OLS model using two partitions and
three fold CV on each partition. Note that by passing the output array
as an argument during <code class="docutils literal notranslate"><span class="pre">'fit'</span></code>, we perform a fit and transform operation.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mlens.index</span> <span class="kn">import</span> <span class="n">SubsetIndex</span>

<span class="k">def</span> <span class="nf">mse</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">p</span><span class="p">):</span> <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">((</span><span class="n">y</span> <span class="o">-</span> <span class="n">p</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span>

<span class="n">indexer</span> <span class="o">=</span> <span class="n">SubsetIndex</span><span class="p">(</span><span class="n">partitions</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">folds</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">)</span>
<span class="n">learner</span> <span class="o">=</span> <span class="n">Learner</span><span class="p">(</span><span class="n">estimator</span><span class="o">=</span><span class="n">OLS</span><span class="p">(),</span>
                  <span class="n">indexer</span><span class="o">=</span><span class="n">indexer</span><span class="p">,</span>
                  <span class="n">name</span><span class="o">=</span><span class="s1">&#39;subsemble-ols&#39;</span><span class="p">,</span>
                  <span class="n">scorer</span><span class="o">=</span><span class="n">mse</span><span class="p">,</span>
                  <span class="n">verbose</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

<span class="n">job</span><span class="o">.</span><span class="n">job</span> <span class="o">=</span> <span class="s1">&#39;fit&#39;</span>
<span class="n">job</span><span class="o">.</span><span class="n">predict_out</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">2</span><span class="p">))</span>

<span class="n">learner</span><span class="o">.</span><span class="n">setup</span><span class="p">(</span><span class="n">job</span><span class="o">.</span><span class="n">predict_in</span><span class="p">,</span> <span class="n">job</span><span class="o">.</span><span class="n">targets</span><span class="p">,</span> <span class="n">job</span><span class="o">.</span><span class="n">job</span><span class="p">)</span>
<span class="k">for</span> <span class="n">sub_learner</span> <span class="ow">in</span> <span class="n">learner</span><span class="p">(</span><span class="n">job</span><span class="o">.</span><span class="n">args</span><span class="p">(),</span> <span class="s1">&#39;main&#39;</span><span class="p">):</span>
    <span class="n">sub_learner</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
    <span class="k">print</span><span class="p">(</span><span class="s1">&#39;Output:&#39;</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="n">job</span><span class="o">.</span><span class="n">predict_out</span><span class="p">)</span>
    <span class="k">print</span><span class="p">()</span>

<span class="n">learner</span><span class="o">.</span><span class="n">collect</span><span class="p">()</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>subsemble-ols.0.0              done | 00:00:00
Output:
[[0. 0.]
 [0. 0.]
 [0. 0.]
 [0. 0.]
 [0. 0.]
 [0. 0.]
 [0. 0.]
 [0. 0.]
 [0. 0.]
 [0. 0.]]

subsemble-ols.1.0              done | 00:00:00
Output:
[[0. 0.]
 [0. 0.]
 [0. 0.]
 [0. 0.]
 [0. 0.]
 [0. 0.]
 [0. 0.]
 [0. 0.]
 [0. 0.]
 [0. 0.]]

subsemble-ols.0.1              done | 00:00:00
Output:
[[ 1.50099289  0.        ]
 [ 1.17185463  0.        ]
 [ 0.84271638  0.        ]
 [ 0.          0.        ]
 [ 0.          0.        ]
 [-0.14469839  0.        ]
 [-0.47383665  0.        ]
 [-0.8029749   0.        ]
 [ 0.          0.        ]
 [ 0.          0.        ]]

subsemble-ols.0.2              done | 00:00:00
Output:
[[ 1.50099289  0.        ]
 [ 1.17185463  0.        ]
 [ 0.84271638  0.        ]
 [-0.0582686   0.        ]
 [-0.30154554  0.        ]
 [-0.14469839  0.        ]
 [-0.47383665  0.        ]
 [-0.8029749   0.        ]
 [-1.27465332  0.        ]
 [-1.51793026  0.        ]]

subsemble-ols.1.1              done | 00:00:00
Output:
[[ 1.50099289  6.98188955]
 [ 1.17185463  6.21497354]
 [ 0.84271638  5.44805754]
 [-0.0582686   0.        ]
 [-0.30154554  0.        ]
 [-0.14469839  3.14730951]
 [-0.47383665  2.3803935 ]
 [-0.8029749   1.61347749]
 [-1.27465332  0.        ]
 [-1.51793026  0.        ]]

subsemble-ols.1.2              done | 00:00:00
Output:
[[ 1.50099289  6.98188955]
 [ 1.17185463  6.21497354]
 [ 0.84271638  5.44805754]
 [-0.0582686   1.14782989]
 [-0.30154554  1.00228074]
 [-0.14469839  3.14730951]
 [-0.47383665  2.3803935 ]
 [-0.8029749   1.61347749]
 [-1.27465332  0.42008412]
 [-1.51793026  0.27453496]]
</pre></div>
</div>
<p>Each sub-learner records fit and predict times during fitting, and if
a scorer is passed scores the predictions as well. The learner aggregates
this data into a <code class="docutils literal notranslate"><span class="pre">raw_data</span></code> attribute in the form of a list.
More conveniently, the <code class="docutils literal notranslate"><span class="pre">data</span></code> attribute returns a dict with a specialized
representation that gives a tabular output directly:
Standard data is fit time (<code class="docutils literal notranslate"><span class="pre">ft</span></code>), predict time (<code class="docutils literal notranslate"><span class="pre">pr</span></code>).
If a scorer was passed to the learner, cross-validated test set prediction
scores are computed. For brevity, <code class="docutils literal notranslate"><span class="pre">-m</span></code> denotes the mean and <code class="docutils literal notranslate"><span class="pre">-s</span></code>
denotes standard deviation.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">print</span><span class="p">(</span><span class="s2">&quot;Data:</span><span class="se">\n</span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">learner</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Data:
                    score-m  score-s  ft-m  ft-s  pt-m  pt-s
subsemble-ols  0       1.45     0.45  0.00  0.00  0.00  0.00
subsemble-ols  1       9.34     9.02  0.00  0.00  0.00  0.00
</pre></div>
</div>
</div>
<div class="section" id="preprocessing">
<h3>Preprocessing<a class="headerlink" href="#preprocessing" title="Permalink to this headline">¶</a></h3>
<p>We can easily create a preprocessing pipeline before fitting the estimator.
In general, several estimators will share the same preprocessing pipeline,
so we don’t want to pipeline the transformations in the estimator itself–
this will result in duplicate transformers.</p>
<p>As with estimators, transformers too define a computational sub-graph given
a cross-validation strategy. Preprocessing pipelines are therefore wrapped
by the <code class="xref py py-class docutils literal notranslate"><span class="pre">Transformer</span></code> class, which is similar to the <code class="xref py py-class docutils literal notranslate"><span class="pre">Learner</span></code>
class. The input to the Transformer is a <code class="xref py py-class docutils literal notranslate"><span class="pre">Pipeline</span></code> instance that holds the
preprocessing pipeline.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">When constructing a <code class="xref py py-class docutils literal notranslate"><span class="pre">Pipeline</span></code> for use with the <code class="xref py py-class docutils literal notranslate"><span class="pre">Transformer</span></code>,
the <code class="docutils literal notranslate"><span class="pre">return_y</span></code> argument must be <code class="docutils literal notranslate"><span class="pre">True</span></code>.</p>
</div>
<p>To link the transformer’s sub-graph with the learner’s sub-graph,
we set the <code class="docutils literal notranslate"><span class="pre">preprocess</span></code> argument of the learner equal to the <code class="docutils literal notranslate"><span class="pre">name</span></code>
of the <code class="xref py py-class docutils literal notranslate"><span class="pre">Transformer</span></code>. Note that any number of learners can share
the same transformer and in fact should when the same preprocessing is desired.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mlens.utils.dummy</span> <span class="kn">import</span> <span class="n">Scale</span>
<span class="kn">from</span> <span class="nn">mlens.parallel</span> <span class="kn">import</span> <span class="n">Transformer</span><span class="p">,</span> <span class="n">Pipeline</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">([(</span><span class="s1">&#39;trans&#39;</span><span class="p">,</span> <span class="n">Scale</span><span class="p">())],</span> <span class="n">return_y</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

<span class="n">transformer</span> <span class="o">=</span> <span class="n">Transformer</span><span class="p">(</span><span class="n">estimator</span><span class="o">=</span><span class="n">pipeline</span><span class="p">,</span>
                          <span class="n">indexer</span><span class="o">=</span><span class="n">indexer</span><span class="p">,</span>
                          <span class="n">name</span><span class="o">=</span><span class="s1">&#39;sc&#39;</span><span class="p">,</span>
                          <span class="n">verbose</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</pre></div>
</div>
<p>To build the learner we pass the <code class="docutils literal notranslate"><span class="pre">name</span></code> of the transformer as
the <code class="docutils literal notranslate"><span class="pre">preprocess</span></code> argument:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">learner</span> <span class="o">=</span> <span class="n">Learner</span><span class="p">(</span><span class="n">estimator</span><span class="o">=</span><span class="n">OLS</span><span class="p">(),</span>
                  <span class="n">preprocess</span><span class="o">=</span><span class="s1">&#39;sc&#39;</span><span class="p">,</span>
                  <span class="n">indexer</span><span class="o">=</span><span class="n">indexer</span><span class="p">,</span>
                  <span class="n">scorer</span><span class="o">=</span><span class="n">mse</span><span class="p">,</span>
                  <span class="n">verbose</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</pre></div>
</div>
<p>We now repeat the above process to fit the learner, starting with fitting
the transformer. By using the <code class="xref py py-class docutils literal notranslate"><span class="pre">Job</span></code> class, we can write task-agnostic
boiler-plate code. Note that the transformer is called as an
<code class="docutils literal notranslate"><span class="pre">'auxiliary'</span></code> task, while the learner is called as the <code class="docutils literal notranslate"><span class="pre">'main'</span></code> task.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Reset the prediction output array</span>
<span class="n">job</span><span class="o">.</span><span class="n">predict_out</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">2</span><span class="p">))</span>

<span class="n">transformer</span><span class="o">.</span><span class="n">setup</span><span class="p">(</span><span class="n">job</span><span class="o">.</span><span class="n">predict_in</span><span class="p">,</span> <span class="n">job</span><span class="o">.</span><span class="n">targets</span><span class="p">,</span> <span class="n">job</span><span class="o">.</span><span class="n">job</span><span class="p">)</span>
<span class="n">learner</span><span class="o">.</span><span class="n">setup</span><span class="p">(</span><span class="n">job</span><span class="o">.</span><span class="n">predict_in</span><span class="p">,</span> <span class="n">job</span><span class="o">.</span><span class="n">targets</span><span class="p">,</span> <span class="n">job</span><span class="o">.</span><span class="n">job</span><span class="p">)</span>

<span class="c1"># Turn split off when you don&#39;t want the args() call to spawn a new sub-cache</span>
<span class="n">job</span><span class="o">.</span><span class="n">split</span> <span class="o">=</span> <span class="bp">False</span>
<span class="k">for</span> <span class="n">subtransformer</span> <span class="ow">in</span> <span class="n">transformer</span><span class="p">(</span><span class="n">job</span><span class="o">.</span><span class="n">args</span><span class="p">(),</span> <span class="s1">&#39;auxiliary&#39;</span><span class="p">):</span>
    <span class="n">subtransformer</span><span class="p">()</span>

<span class="k">for</span> <span class="n">sublearner</span> <span class="ow">in</span> <span class="n">learner</span><span class="p">(</span><span class="n">job</span><span class="o">.</span><span class="n">args</span><span class="p">(),</span> <span class="s1">&#39;main&#39;</span><span class="p">):</span>
    <span class="n">sublearner</span><span class="p">()</span>

<span class="n">transformer</span><span class="o">.</span><span class="n">collect</span><span class="p">()</span>
<span class="n">learner</span><span class="o">.</span><span class="n">collect</span><span class="p">()</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>sc.0.0                         done | 00:00:00
sc.1.0                         done | 00:00:00
sc.0.1                         done | 00:00:00
sc.0.2                         done | 00:00:00
sc.1.1                         done | 00:00:00
sc.1.2                         done | 00:00:00
sc.learner-1.0.0               done | 00:00:00
sc.learner-1.1.0               done | 00:00:00
sc.learner-1.0.1               done | 00:00:00
sc.learner-1.0.2               done | 00:00:00
sc.learner-1.1.1               done | 00:00:00
sc.learner-1.1.2               done | 00:00:00
</pre></div>
</div>
<p>Note that the cache now contains the transformers as well:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">print</span><span class="p">(</span><span class="s2">&quot;Cache:&quot;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">job</span><span class="o">.</span><span class="n">dir</span><span class="p">[</span><span class="s1">&#39;task_</span><span class="si">%i</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">job</span><span class="o">.</span><span class="n">_n_dir</span><span class="p">]:</span>
    <span class="k">print</span><span class="p">(</span><span class="s1">&#39;{:20}{}&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="o">*</span><span class="n">item</span><span class="p">))</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Cache:
sc.0.0              &lt;mlens.parallel.learner.IndexedEstimator object at 0x115b4a7d8&gt;
sc.1.0              &lt;mlens.parallel.learner.IndexedEstimator object at 0x115b4a570&gt;
sc.0.1              &lt;mlens.parallel.learner.IndexedEstimator object at 0x115b4a468&gt;
sc.0.2              &lt;mlens.parallel.learner.IndexedEstimator object at 0x115b4a830&gt;
sc.1.1              &lt;mlens.parallel.learner.IndexedEstimator object at 0x115b4a6d0&gt;
sc.1.2              &lt;mlens.parallel.learner.IndexedEstimator object at 0x115b4a728&gt;
sc.learner-1.0.0    &lt;mlens.parallel.learner.IndexedEstimator object at 0x115b4a410&gt;
sc.learner-1.1.0    &lt;mlens.parallel.learner.IndexedEstimator object at 0x115b4a780&gt;
sc.learner-1.0.1    &lt;mlens.parallel.learner.IndexedEstimator object at 0x115b4a8e0&gt;
sc.learner-1.0.2    &lt;mlens.parallel.learner.IndexedEstimator object at 0x115b4a938&gt;
sc.learner-1.1.1    &lt;mlens.parallel.learner.IndexedEstimator object at 0x115b4a990&gt;
sc.learner-1.1.2    &lt;mlens.parallel.learner.IndexedEstimator object at 0x115b4a9e8&gt;
</pre></div>
</div>
<p>And estimation data is collected on a partition basis:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">print</span><span class="p">(</span><span class="s2">&quot;Data:</span><span class="se">\n</span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">learner</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Data:
                    score-m  score-s  ft-m  ft-s  pt-m  pt-s
sc  learner-1  0       2.19     0.92  0.00  0.00  0.00  0.00
sc  learner-1  1       7.76     7.37  0.00  0.00  0.00  0.00
</pre></div>
</div>
</div>
<div class="section" id="parallel-estimation">
<h3>Parallel estimation<a class="headerlink" href="#parallel-estimation" title="Permalink to this headline">¶</a></h3>
<p>Since the learner and transformer class do not perform estimations themselves,
we are free to modify the estimation behavior. For instance, to parallelize
estimation with several learners, we don’t want a nested loop over each learner,
but instead flatten the for loops for maximal concurrency.
This is the topic of our next walk through. Here we show how to parallelize
estimation with a single learner using multiple threads:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">multiprocessing.dummy</span> <span class="kn">import</span> <span class="n">Pool</span>

<span class="k">def</span> <span class="nf">run</span><span class="p">(</span><span class="n">est</span><span class="p">):</span> <span class="n">est</span><span class="p">()</span>

<span class="n">args</span> <span class="o">=</span> <span class="n">job</span><span class="o">.</span><span class="n">args</span><span class="p">()</span>
<span class="n">job</span><span class="o">.</span><span class="n">predict_out</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">2</span><span class="p">))</span>
<span class="n">job</span><span class="o">.</span><span class="n">job</span> <span class="o">=</span> <span class="s1">&#39;predict&#39;</span>
<span class="n">Pool</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">run</span><span class="p">,</span> <span class="nb">list</span><span class="p">(</span><span class="n">learner</span><span class="p">(</span><span class="n">args</span><span class="p">,</span> <span class="s1">&#39;main&#39;</span><span class="p">)))</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>sc.learner-1.0.0               done | 00:00:00
sc.learner-1.1.0               done | 00:00:00
sc.learner-1.0.1               done | 00:00:00
sc.learner-1.1.1               done | 00:00:00
sc.learner-1.0.2               done | 00:00:00
sc.learner-1.1.2               done | 00:00:00
</pre></div>
</div>
<p>For a slightly more high-level API for parallel computation on a single
instance (of any accepted class), we can turn to the <code class="xref py py-func docutils literal notranslate"><span class="pre">run()</span></code> function.
This function takes care of argument specification, array creation and all
details we would otherwise need to attend to. For instance, to transform
a dataset using the preprocessing pipeline fitted on the full training set,
use <code class="xref py py-func docutils literal notranslate"><span class="pre">run()</span></code> to call <code class="docutils literal notranslate"><span class="pre">predict</span></code>:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mlens.parallel</span> <span class="kn">import</span> <span class="n">run</span>

<span class="k">print</span><span class="p">(</span>
    <span class="n">run</span><span class="p">(</span><span class="n">transformer</span><span class="p">,</span> <span class="s1">&#39;predict&#39;</span><span class="p">,</span> <span class="n">X</span><span class="p">)</span>
<span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>sc.0.0                         done | 00:00:00
sc.1.0                         done | 00:00:00
[[ -4.  -4. -14. -14.]
 [ -2.  -2. -12. -12.]
 [  0.   0. -10. -10.]
 [  2.   2.  -8.  -8.]
 [  4.   4.  -6.  -6.]
 [  6.   6.  -4.  -4.]
 [  8.   8.  -2.  -2.]
 [ 10.  10.   0.   0.]
 [ 12.  12.   2.   2.]
 [ 14.  14.   4.   4.]]
</pre></div>
</div>
<p>Next we handle several learners by grouping them in a layer in the
<a class="reference internal" href="layer.html#layer-tutorial"><span class="std std-ref">layer mechanics tutorial</span></a>.</p>
<p><strong>Total running time of the script:</strong> ( 0 minutes  0.192 seconds)</p>
<div class="sphx-glr-footer class sphx-glr-footer-example docutils container" id="sphx-glr-download-tutorials-learner-py">
<div class="sphx-glr-download docutils container">
<a class="reference download internal" href="../_downloads/learner.py" download=""><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">learner.py</span></code></a></div>
<div class="sphx-glr-download docutils container">
<a class="reference download internal" href="../_downloads/learner.ipynb" download=""><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">learner.ipynb</span></code></a></div>
</div>
<p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.readthedocs.io">Gallery generated by Sphinx-Gallery</a></p>
</div>
</div>
</div>


           </div>
           
          </div>
          <footer>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2017, Sebastian Flennerhag.

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'../',
            VERSION:'0.2.2',
            LANGUAGE:'None',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'.html',
            HAS_SOURCE:  true,
            SOURCELINK_SUFFIX: '.txt'
        };
    </script>
      <script type="text/javascript" src="../_static/jquery.js"></script>
      <script type="text/javascript" src="../_static/underscore.js"></script>
      <script type="text/javascript" src="../_static/doctools.js"></script>
      <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

  

  <script type="text/javascript" src="../_static/js/theme.js"></script>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>